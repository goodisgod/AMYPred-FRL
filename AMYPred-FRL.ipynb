{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4642b79a",
   "metadata": {},
   "source": [
    "#### AMYPred-FRL is a novel approach for accurate prediction of amyloid proteins by using feature representation learning\n",
    "Charoenkwan, P., Ahmed, S., Nantasenamat, C. et al. AMYPred-FRL is a novel approach for accurate prediction of amyloid proteins by using feature representation learning. Sci Rep 12, 7697 (2022). https://doi.org/10.1038/s41598-022-11897-z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "754005d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" Created on Mon Dec 16 14: 23:14 2019\n",
    "@author\n",
    ": logistics\n",
    "\"\"\"\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import re, os, sys\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a85fe4",
   "metadata": {},
   "source": [
    "You can modify the read_protein_sequences function to also accept a string as input by adding an optional parameter called input_string with a default value of None. You can then check whether the input_string is provided or not, and if it is provided, use it instead of reading the file. Here's the modified function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd8fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function read_protein_sequences with a single argument 'file'\n",
    "def read_protein_sequences(file=None, input_string=None):\n",
    "    if file and input_string:\n",
    "        raise ValueError(\"Both 'file' and 'input_string' cannot be used at the same time.\")\n",
    "    if not file and not input_string:\n",
    "        raise ValueError(\"Either 'file' or 'input_string' must be provided.\")\n",
    "\n",
    "    if file:\n",
    "        if os.path.exists(file) == False:\n",
    "            print('Error: file %s does not exist.' % file)\n",
    "            sys.exit(1)\n",
    "\n",
    "        with open(file) as f:\n",
    "            records = f.read()\n",
    "    else:\n",
    "        records = input_string\n",
    "    \n",
    "    if re.search('>', records) == None:\n",
    "        print('Error: the input seems not in FASTA format!')\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    # Split the records into individual FASTA sequences\n",
    "    records = records.split('>')[1:]\n",
    "\n",
    "    # Initialize an empty list to store the extracted sequences\n",
    "    fasta_sequences = []\n",
    "\n",
    "    # Iterate through the records and process each sequence\n",
    "    for fasta in records:\n",
    "        # Split the sequence by newline characters\n",
    "        array = fasta.split('\\n')\n",
    "        # Extract the header and the sequence, replacing any non-standard amino acids with '-'\n",
    "        header, sequence = array[0].split()[0], re.sub('[^ACDEFGHIKLMNPQRSTVWY-]', '-', ''.join(array[1:]).upper())\n",
    "        # Split the header using the '|' character\n",
    "        header_array = header.split('|')\n",
    "        # Extract the name from the header\n",
    "        name = header_array[0]\n",
    "        # Append the name and sequence as a list to the fasta_sequences list\n",
    "        fasta_sequences.append([name, sequence])\n",
    "\n",
    "    # Return the list of fasta_sequences\n",
    "    return fasta_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47eb437",
   "metadata": {},
   "source": [
    "# Feature Extraction Methods\n",
    "I'll provide a brief explanation of each of these feature extraction methods, which are primarily used in bioinformatics and chemoinformatics to analyze protein or compound sequences:\n",
    "\n",
    "AAC (Amino Acid Composition): AAC calculates the relative frequency of each amino acid in a protein sequence. This method provides a simple representation of a protein's composition by generating a 20-dimensional feature vector.\n",
    "\n",
    "DPC (Dipeptide Composition): DPC calculates the frequency of all possible dipeptide combinations (400 total) in a protein sequence. This approach captures local sequence-order information and results in a 400-dimensional feature vector.\n",
    "\n",
    "APAAC (Amphiphilic Pseudo Amino Acid Composition): APAAC combines AAC with amphiphilic properties of amino acids. The method considers the hydrophobicity and hydrophilicity patterns of protein sequences, resulting in a higher-dimensional feature vector that captures both composition and physicochemical properties.\n",
    "\n",
    "CTDC (Composition, Transition, and Distribution of Chemical Groups): CTDC is a feature extraction method for protein sequences that incorporates the composition, transition, and distribution of different chemical groups (e.g., polar, nonpolar) within the sequence.\n",
    "\n",
    "CTDD (Composition, Transition, and Distribution of Dipeptides): CTDD is similar to CTDC, but it focuses on dipeptides. It captures the composition, transition, and distribution of dipeptide groups within the protein sequence.\n",
    "\n",
    "CTDT (Composition, Transition, and Distribution of Tripeptides): CTDT extends the concept of CTDC and CTDD to tripeptides. It calculates the composition, transition, and distribution of tripeptide groups within the protein sequence.\n",
    "\n",
    "GAAC (Grouped Amino Acid Composition): GAAC groups amino acids according to their physicochemical properties (e.g., size, charge, hydrophobicity) and calculates the relative frequency of these groups in the protein sequence. This approach results in a lower-dimensional feature vector compared to AAC.\n",
    "\n",
    "KSCTriad (K-Spaced Amino Acid Pairs Composition with Triads): KSCTriad combines the K-spaced amino acid pairs composition (which considers pairs of amino acids separated by K residues) with a triad-based method that captures local sequence information. This results in a high-dimensional feature vector.\n",
    "\n",
    "CTriad (Conjoint Triad): CTriad represents a protein sequence by considering the frequency of overlapping triads of amino acids. It groups amino acids based on their physicochemical properties and encodes the sequence using a 343-dimensional feature vector.\n",
    "\n",
    "DDE (Dragon Descriptor Extraction): DDE is a chemoinformatics approach that extracts molecular descriptors for chemical compounds. Dragon is a software package that calculates a wide range of molecular descriptors (e.g., topological, geometrical, electronic, and thermodynamic properties) to characterize compounds.\n",
    "\n",
    "PAAC (Pseudo Amino Acid Composition): PAAC is a protein feature extraction method that combines the amino acid composition with additional sequence-order information. The resulting feature vector captures both the composition and the physicochemical properties of the protein sequence.\n",
    "\n",
    "These methods help analyze protein or compound sequences, enabling researchers to study their properties, classify them, and predict their function or interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f96ac39",
   "metadata": {},
   "source": [
    "Define the 20 amino acids.\n",
    "2-3. Initialize empty lists encodings and header.\n",
    "4-6. Loop through amino acids and append each amino acid to the header list.\n",
    "7-16. Loop through protein sequences in fastas, removing gaps, counting amino acid occurrences, and computing their relative frequencies. Append the computed frequencies to the encodings list.\n",
    "Return the encodings NumPy array and the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3204438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function computes the amino acid composition of the given protein sequences. It takes a list of protein sequences as input, calculates the relative frequency of each amino acid in the sequence, and returns a NumPy array of the amino acid compositions along with their headers.\n",
    "def AAC(fastas, **kw):\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    #AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for i in AA:\n",
    "        header.append(i)\n",
    "    #encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        count = Counter(sequence)\n",
    "        for key in count:\n",
    "            count[key] = count[key]/len(sequence)\n",
    "        code = []\n",
    "        for aa in AA:\n",
    "            code.append(count[aa])\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b9ec5",
   "metadata": {},
   "source": [
    "Define the 20 amino acids.\n",
    "Read the AAindex data file.\n",
    "3-9. Parse the AAindex data file and store the property values and names in the lists AAindex and AAindexName.\n",
    "10-16. If user-defined properties are provided, filter the parsed AAindex data to only include the specified properties.\n",
    "17-19. Loop through AAindex names and append each property name to the header list.\n",
    "20-35. Loop through protein sequences in fastas and compute the average property value for each sequence. Append the computed values to the encodings list.\n",
    "Return the encodings NumPy array and the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbdfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the AAINDEX features, which are based on various physicochemical and biological properties of amino acids. It takes a list of protein sequences and an optional list of properties as input, calculates the average property value for each protein sequence, and returns a NumPy array of the AAINDEX features along with their headers.\n",
    "def AAINDEX(fastas, props=None, **kw):\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    fileAAindex = 'input/data/AAindex.txt'\n",
    "    with open(fileAAindex) as f:\n",
    "        records = f.readlines()[1:]\n",
    "\n",
    "    AAindex = []\n",
    "    AAindexName = []\n",
    "    for i in records:\n",
    "        AAindex.append(i.rstrip().split()[1:] if i.rstrip() != '' else None)\n",
    "        AAindexName.append(i.rstrip().split()[0] if i.rstrip() != '' else None)\n",
    "\n",
    "    index = {}\n",
    "    for i in range(len(AA)):\n",
    "        index[AA[i]] = i\n",
    "\n",
    "    #  use the user inputed properties\n",
    "    if props:\n",
    "        tmpIndexNames = []\n",
    "        tmpIndex = []\n",
    "        for p in props:\n",
    "            if AAindexName.index(p) != -1:\n",
    "                tmpIndexNames.append(p)\n",
    "                tmpIndex.append(AAindex[AAindexName.index(p)])\n",
    "        if len(tmpIndexNames) != 0:\n",
    "            AAindexName = tmpIndexNames\n",
    "            AAindex = tmpIndex\n",
    "\n",
    "    header = []\n",
    "    for idName in AAindexName:\n",
    "        header.append(idName)\n",
    "\n",
    "    encodings = []\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = []\n",
    "\n",
    "        for j in AAindex:\n",
    "            tmp = 0\n",
    "            for aa in sequence:\n",
    "                if aa == '-':\n",
    "                    tmp = tmp + 0\n",
    "                else:\n",
    "                    tmp = tmp + float(j[index[aa]])\n",
    "            code.append(tmp/len(sequence))\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903af51b",
   "metadata": {},
   "source": [
    "Define the data file for pseudo amino acid composition properties.\n",
    "2-9. Read and parse the data file, storing amino acid properties and property names in the lists AAProperty and AAPropertyNames.\n",
    "10-13. Normalize the amino acid properties.\n",
    "14-20. Initialize empty lists encodings and header. Loop through amino acids and property names, appending them to the header list.\n",
    "21-38. Loop through protein sequences in fastas, removing gaps, and compute the correlation factors between amino acid properties and sequence positions. Append the computed factors to the encodings list.\n",
    "Return the encodings NumPy array and the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620810ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the amphiphilic pseudo amino acid composition of the given protein sequences. It takes a list of protein sequences, an optional lambda value (default 10), and an optional weight factor (default 0.05) as input. The function calculates the correlation factors between amino acid properties and sequence positions, and returns a NumPy array of the APAAC features along with their headers.\n",
    "def APAAC(fastas, lambdaValue=10, w=0.05, **kw):\n",
    "    dataFile = 'data/PAAC.txt'\n",
    "\n",
    "    with open(dataFile) as f:\n",
    "        records = f.readlines()\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records) - 1):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j - meanI) ** 2 for j in i]) / 20)\n",
    "        AAProperty1.append([(j - meanI) / fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for i in AA:\n",
    "        header.append('Pc1.' + i)\n",
    "    for j in range(1, lambdaValue + 1):\n",
    "        for i in AAPropertyNames:\n",
    "            header.append('Pc2.' + i + '.' + str(j))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        theta = []\n",
    "\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            for j in range(len(AAProperty1)):\n",
    "                theta.append(sum([AAProperty1[j][AADict[sequence[k]]] * AAProperty1[j][AADict[sequence[k + n]]] for k in\n",
    "                                  range(len(sequence) - n)]) / (len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [w * value / (1 + w * sum(theta)) for value in theta]\n",
    "\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b706f35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa8c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASA required SPINEX external program\n",
    "# BINARY encoding required same protein sequence length\n",
    "\n",
    "# This function computes the BLOSUM62 encoding for a given set of protein sequences. BLOSUM62 is a substitution matrix representing the probabilities of amino acid substitutions in proteins. The input fastas is a list of tuples containing the protein name and sequence, and the function returns a numpy array of the computed encodings and a list of headers.\n",
    "def BLOSUM62(fastas, **kw):\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    blosum62 = {\n",
    "        'A': [4,  -1, -2, -2, 0,  -1, -1, 0, -2,  -1, -1, -1, -1, -2, -1, 1,  0,  -3, -2, 0],  # A\n",
    "        'R': [-1, 5,  0,  -2, -3, 1,  0,  -2, 0,  -3, -2, 2,  -1, -3, -2, -1, -1, -3, -2, -3], # R\n",
    "        'N': [-2, 0,  6,  1,  -3, 0,  0,  0,  1,  -3, -3, 0,  -2, -3, -2, 1,  0,  -4, -2, -3], # N\n",
    "        'D': [-2, -2, 1,  6,  -3, 0,  2,  -1, -1, -3, -4, -1, -3, -3, -1, 0,  -1, -4, -3, -3], # D\n",
    "        'C': [0,  -3, -3, -3, 9,  -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1], # C\n",
    "        'Q': [-1, 1,  0,  0,  -3, 5,  2,  -2, 0,  -3, -2, 1,  0,  -3, -1, 0,  -1, -2, -1, -2], # Q\n",
    "        'E': [-1, 0,  0,  2,  -4, 2,  5,  -2, 0,  -3, -3, 1,  -2, -3, -1, 0,  -1, -3, -2, -2], # E\n",
    "        'G': [0,  -2, 0,  -1, -3, -2, -2, 6,  -2, -4, -4, -2, -3, -3, -2, 0,  -2, -2, -3, -3], # G\n",
    "        'H': [-2, 0,  1,  -1, -3, 0,  0,  -2, 8,  -3, -3, -1, -2, -1, -2, -1, -2, -2, 2,  -3], # H\n",
    "        'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3, 4,  2,  -3, 1,  0,  -3, -2, -1, -3, -1, 3],  # I\n",
    "        'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3, 2,  4,  -2, 2,  0,  -3, -2, -1, -2, -1, 1],  # L\n",
    "        'K': [-1, 2,  0,  -1, -3, 1,  1,  -2, -1, -3, -2, 5,  -1, -3, -1, 0,  -1, -3, -2, -2], # K\n",
    "        'M': [-1, -1, -2, -3, -1, 0,  -2, -3, -2, 1,  2,  -1, 5,  0,  -2, -1, -1, -1, -1, 1],  # M\n",
    "        'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1, 0,  0,  -3, 0,  6,  -4, -2, -2, 1,  3,  -1], # F\n",
    "        'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4, 7,  -1, -1, -4, -3, -2], # P\n",
    "        'S': [1,  -1, 1,  0,  -1, 0,  0,  0,  -1, -2, -2, 0,  -1, -2, -1, 4,  1,  -3, -2, -2], # S\n",
    "        'T': [0,  -1, 0,  -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1, 1,  5,  -2, -2, 0],  # T\n",
    "        'W': [-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1, 1,  -4, -3, -2, 11, 2,  -3], # W\n",
    "        'Y': [-2, -2, -2, -3, -2, -1, -2, -3, 2,  -1, -1, -2, -1, 3,  -3, -2, -2, 2,  7,  -1], # Y\n",
    "        'V': [0,  -3, -3, -3, -1, -2, -2, -3, -3, 3,  1,  -2, 1,  -1, -2, -2, 0,  -3, -1, 4],  # V\n",
    "        '-': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # -\n",
    "    }\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for i in range(0,20):\n",
    "        header.append('blosum62.F'+str(AA[i]))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = np.asarray([0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
    "        for aa in sequence:\n",
    "            code = code + np.asarray(blosum62[aa])\n",
    "        encodings.append(list(code/len(sequence)))\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a70b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates group pairs for a given group of amino acids. The input groupKey is a list of keys representing groups of amino acids, and the function returns a dictionary with group pairs as keys and their initial values set to 0.\n",
    "def generateGroupPairs(groupKey):\n",
    "    gPair = {}\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPair[key1 + '.' + key2] = 0\n",
    "    return gPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc92b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the Composition of k-Spaced Amino Acid Group Pairs (CKSAAGP) encoding for a given set of protein sequences. The input fastas is a list of tuples containing the protein name and sequence, and the function returns a numpy array of the computed encodings and a list of headers.\n",
    "def CKSAAGP(fastas, gap=3, **kw):\n",
    "    if gap < 0:\n",
    "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    group = {\n",
    "        'alphaticr': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'postivecharger': 'KRH',\n",
    "        'negativecharger': 'DE',\n",
    "        'uncharger': 'STCPNQ'\n",
    "    }\n",
    "\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    gPairIndex = []\n",
    "    for key1 in groupKey:\n",
    "        for key2 in groupKey:\n",
    "            gPairIndex.append(key1 + '.' + key2)\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for g in range(gap + 1):\n",
    "        for p in gPairIndex:\n",
    "            header.append(p + '.gap' + str(g))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for g in range(gap + 1):\n",
    "            gPair = generateGroupPairs(groupKey)\n",
    "            sum = 0\n",
    "            for p1 in range(len(sequence)):\n",
    "                p2 = p1 + g + 1\n",
    "                if p2 < len(sequence) and sequence[p1] in AA and sequence[p2] in AA:\n",
    "                    gPair[index[sequence[p1]] + '.' + index[sequence[p2]]] = gPair[index[sequence[p1]] + '.' + index[\n",
    "                        sequence[p2]]] + 1\n",
    "                    sum = sum + 1\n",
    "\n",
    "            if sum == 0:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(0)\n",
    "            else:\n",
    "                for gp in gPairIndex:\n",
    "                    code.append(gPair[gp] / sum)\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89f642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the Group-based Dipeptide Composition (GDPC) encoding for a given set of protein sequences. The input fastas is a list of tuples containing the protein name and sequence, and the function returns a numpy array of the computed encodings and a list of headers.\n",
    "def GDPC(fastas, **kw):\n",
    "    group = {\n",
    "        'alphaticr': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'postivecharger': 'KRH',\n",
    "        'negativecharger': 'DE',\n",
    "        'uncharger': 'STCPNQ'\n",
    "    }\n",
    "\n",
    "    groupKey = group.keys()\n",
    "    baseNum = len(groupKey)\n",
    "    dipeptide = [g1 + '.' + g2 for g1 in groupKey for g2 in groupKey]\n",
    "\n",
    "    index = {}\n",
    "    for key in groupKey:\n",
    "        for aa in group[key]:\n",
    "            index[aa] = key\n",
    "\n",
    "    encodings = []\n",
    "    header = []#+dipeptide\n",
    "    #encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "\n",
    "        code = [name]\n",
    "        myDict = {}\n",
    "        for t in dipeptide:\n",
    "            myDict[t] = 0\n",
    "\n",
    "        sum = 0\n",
    "        for j in range(len(sequence) - 2 + 1):\n",
    "            myDict[index[sequence[j]] + '.' + index[sequence[j + 1]]] = myDict[index[sequence[j]] + '.' + index[\n",
    "                sequence[j + 1]]] + 1\n",
    "            sum = sum + 1\n",
    "\n",
    "        if sum == 0:\n",
    "            for t in dipeptide:\n",
    "                code.append(0)\n",
    "        else:\n",
    "            for t in dipeptide:\n",
    "                code.append(myDict[t] / sum)\n",
    "        encodings.append(code)\n",
    "\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52487cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the Group-based Amino Acid Composition (GAAC) encoding for a given set of protein sequences. The input fastas is a list of tuples containing the protein name and sequence, and the function returns a numpy array of the computed encodings and a list of headers.\n",
    "def GAAC(fastas, **kw):\n",
    "    group = {\n",
    "        'alphatic': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'postivecharge': 'KRH',\n",
    "        'negativecharge': 'DE',\n",
    "        'uncharge': 'STCPNQ'\n",
    "    }\n",
    "\n",
    "    groupKey = group.keys()\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for key in groupKey:\n",
    "        header.append(key)\n",
    "\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence= i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        count = Counter(sequence)\n",
    "        myDict = {}\n",
    "        for key in groupKey:\n",
    "            for aa in group[key]:\n",
    "                myDict[key] = myDict.get(key, 0) + count[aa]\n",
    "\n",
    "        for key in groupKey:\n",
    "            code.append(myDict[key]/len(sequence))\n",
    "        encodings.append(code)\n",
    "\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "# This function computes the Composition of k-Spaced Amino Acid Pairs (CKSAAP) encoding for a given set of protein sequences. The input fastas is a list of tuples containing the protein name and sequence, and the function returns a numpy array of the computed encodings and a list of headers.\n",
    "def CKSAAP(fastas, gap=3, **kw):\n",
    "    if gap < 0:\n",
    "        print('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
    "        return 0\n",
    "\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    encodings = []\n",
    "    aaPairs = []\n",
    "    for aa1 in AA:\n",
    "        for aa2 in AA:\n",
    "            aaPairs.append(aa1 + aa2)\n",
    "\n",
    "    header = []\n",
    "    for g in range(gap + 1):\n",
    "        for aa in aaPairs:\n",
    "            header.append(aa + '.gap' + str(g))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = []\n",
    "        for g in range(gap + 1):\n",
    "            myDict = {}\n",
    "            for pair in aaPairs:\n",
    "                myDict[pair] = 0\n",
    "            sum = 0\n",
    "            for index1 in range(len(sequence)):\n",
    "                index2 = index1 + g + 1\n",
    "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[\n",
    "                    index2] in AA:\n",
    "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
    "                    sum = sum + 1\n",
    "            for pair in aaPairs:\n",
    "                code.append(myDict[pair] / sum)\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0d789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes two sequences as input, and returns the total number of occurrences of elements in seq1 in seq2. It initializes a sum variable to zero and iterates through the elements in seq1, incrementing the sum by the count of that element in seq2.\n",
    "def Count(seq1, seq2):\n",
    "    sum = 0\n",
    "    for aa in seq1:\n",
    "        sum = sum + seq2.count(aa)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77fc9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the amino acid composition properties of the sequences in fastas. It first defines groups of amino acids by their properties, such as charged, aliphatic, aromatic, etc. Then, it calculates the proportion of each property group in each sequence and returns a NumPy array of these proportions and a list of property names.\n",
    "def AACPCP(fastas, **kw):\n",
    "    groups = {\n",
    "        'charged':'DEKHR',\n",
    "        'aliphatic':'ILV',\n",
    "        'aromatic':'FHWY',\n",
    "        'polar':'DERKQN',\n",
    "        'neutral':'AGHPSTY',\n",
    "        'hydrophobic':'CVLIMFW',\n",
    "        'positively-charged':'HKR',\n",
    "        'negatively-charged':'DE',\n",
    "        'tiny':'ACDGST',\n",
    "        'small':'EHILKMNPQV',\n",
    "        'large':'FRWY'\n",
    "    }\n",
    "\n",
    "\n",
    "    property = (\n",
    "    'charged', 'aliphatic', 'aromatic', 'polar',\n",
    "    'neutral', 'hydrophobic', 'positively-charged', 'negatively-charged',\n",
    "    'tiny', 'small', 'large')\n",
    "\n",
    "    encodings = []\n",
    "    header = property\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            c = Count(groups[p], sequence) / len(sequence)\n",
    "            code = code + [c]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), list(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f56cd0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the composition, transition, and distribution of physicochemical properties for the sequences in fastas. It first defines three groups of amino acids for each property. Then, it calculates the proportion of each group for each property in each sequence and returns a NumPy array of these proportions and a list of property names.\n",
    "def CTDC(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for g in range(1, len(groups) + 1):\n",
    "            header.append(p + '.G' + str(g))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            c1 = Count(group1[p], sequence) / len(sequence)\n",
    "            c2 = Count(group2[p], sequence) / len(sequence)\n",
    "            c3 = 1 - c1 - c2\n",
    "            code = code + [c1, c2, c3]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e8e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes an amino acid set aaSet and a sequence as input, and returns a list of percentages representing the position of the first occurrence of each cutoff number (1, 25%, 50%, 75%, and 100%) of amino acids from the set within the sequence. If no amino acid from the set is found in the sequence, it appends 0 to the list.\n",
    "def Count2(aaSet, sequence):\n",
    "    number = 0\n",
    "    for aa in sequence:\n",
    "        if aa in aaSet:\n",
    "            number = number + 1\n",
    "    cutoffNums = [1, math.floor(0.25 * number), math.floor(0.50 * number), math.floor(0.75 * number), number]\n",
    "    cutoffNums = [i if i >=1 else 1 for i in cutoffNums]\n",
    "\n",
    "    code = []\n",
    "    for cutoff in cutoffNums:\n",
    "        myCount = 0\n",
    "        for i in range(len(sequence)):\n",
    "            if sequence[i] in aaSet:\n",
    "                myCount += 1\n",
    "                if myCount == cutoff:\n",
    "                    code.append((i + 1) / len(sequence) * 100)\n",
    "                    break\n",
    "        if myCount == 0:\n",
    "            code.append(0)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f1a652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a list of fasta format protein sequences and optional keyword arguments.\n",
    "# The function computes the Composition, Transition, and Distribution of three groups of amino acids based on different properties like hydrophobicity, normwaalsvolume, polarity, polarizability, charge, secondary structure, and solvent accessibility.\n",
    "# Returns a NumPy array of calculated encoding values and a header list.\n",
    "def CTDD(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for g in ('1', '2', '3'):\n",
    "            for d in ['0', '25', '50', '75', '100']:\n",
    "                header.append(p + '.' + g + '.residue' + d)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence  = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            code = code + Count2(group1[p], sequence) + Count2(group2[p], sequence) + Count2(group3[p], sequence)\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1c5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a list of fasta format protein sequences and optional keyword arguments.\n",
    "# Similar to the CTDD function, it computes the Composition, Transition, and Distribution of three groups of amino acids. However, it focuses on the transitions between the groups rather than the distribution.\n",
    "# Returns a NumPy array of calculated encoding values and a header list.\n",
    "def CTDT(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for tr in ('Tr1221', 'Tr1331', 'Tr2332'):\n",
    "            header.append(p + '.' + tr)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        aaPair = [sequence[j:j + 2] for j in range(len(sequence) - 1)]\n",
    "        for p in property:\n",
    "            c1221, c1331, c2332 = 0, 0, 0\n",
    "            for pair in aaPair:\n",
    "                if (pair[0] in group1[p] and pair[1] in group2[p]) or (pair[0] in group2[p] and pair[1] in group1[p]):\n",
    "                    c1221 = c1221 + 1\n",
    "                    continue\n",
    "                if (pair[0] in group1[p] and pair[1] in group3[p]) or (pair[0] in group3[p] and pair[1] in group1[p]):\n",
    "                    c1331 = c1331 + 1\n",
    "                    continue\n",
    "                if (pair[0] in group2[p] and pair[1] in group3[p]) or (pair[0] in group3[p] and pair[1] in group2[p]):\n",
    "                    c2332 = c2332 + 1\n",
    "            code = code + [c1221/len(aaPair), c1331/len(aaPair), c2332/len(aaPair)]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1c99021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a protein sequence, a gap value, a list of features, and a dictionary mapping amino acids to groups.\n",
    "# The function calculates the K-Spaced Consecutive Triads (KSCT) for the given protein sequence based on the specified gap and features.\n",
    "# Returns a list of computed values.\n",
    "def CalculateKSCTriad(sequence, gap, features, AADict):\n",
    "    res = []\n",
    "    for g in range(gap + 1):\n",
    "        myDict = {}\n",
    "        for f in features:\n",
    "            myDict[f] = 0\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "            if i + g + 1 < len(sequence) and i + 2 * g + 2 < len(sequence):\n",
    "                fea = AADict[sequence[i]] + '.' + AADict[sequence[i + g + 1]] + '.' + AADict[\n",
    "                    sequence[i + 2 * g + 2]]\n",
    "                myDict[fea] = myDict[fea] + 1\n",
    "\n",
    "        maxValue, minValue = max(myDict.values()), min(myDict.values())\n",
    "        for f in features:\n",
    "            res.append((myDict[f] - minValue) / maxValue)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab58bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a list of fasta format protein sequences, a gap value, and optional keyword arguments.\n",
    "# The function computes the K-Spaced Consecutive Triads (KSCT) encoding for each protein sequence in the input list.\n",
    "# Returns a NumPy array of calculated encoding values and a header list.\n",
    "def KSCTriad(fastas, gap=0, **kw):\n",
    "    AAGroup = {\n",
    "        'g1': 'AGV',\n",
    "        'g2': 'ILFP',\n",
    "        'g3': 'YMTS',\n",
    "        'g4': 'HNQW',\n",
    "        'g5': 'RK',\n",
    "        'g6': 'DE',\n",
    "        'g7': 'C'\n",
    "    }\n",
    "\n",
    "    myGroups = sorted(AAGroup.keys())\n",
    "\n",
    "    AADict = {}\n",
    "    for g in myGroups:\n",
    "        for aa in AAGroup[g]:\n",
    "            AADict[aa] = g\n",
    "\n",
    "    features = [f1 + '.' + f2 + '.' + f3 for f1 in myGroups for f2 in myGroups for f3 in myGroups]\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    for g in range(gap + 1):\n",
    "        for f in features:\n",
    "            header.append(f + '.gap' + str(g))\n",
    "\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = [name]\n",
    "        if len(sequence) < 2 * gap + 3:\n",
    "            print('Error: for \"KSCTriad\" encoding, the input fasta sequences should be greater than (2*gap+3). \\n\\n')\n",
    "            return 0\n",
    "        code = code + CalculateKSCTriad(sequence, gap, features, AADict)\n",
    "        encodings.append(code)\n",
    "\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6100ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input: a list of fasta format protein sequences, a gap value, and optional keyword arguments.\n",
    "# The function computes the Consecutive Triads (CT) encoding for each protein sequence in the input list.\n",
    "# Returns a NumPy array of calculated encoding values and a header list.\n",
    "def CTriad(fastas, gap = 0, **kw):\n",
    "    AAGroup = {\n",
    "        'g1': 'AGV',\n",
    "        'g2': 'ILFP',\n",
    "        'g3': 'YMTS',\n",
    "        'g4': 'HNQW',\n",
    "        'g5': 'RK',\n",
    "        'g6': 'DE',\n",
    "        'g7': 'C'\n",
    "    }\n",
    "\n",
    "    myGroups = sorted(AAGroup.keys())\n",
    "\n",
    "    AADict = {}\n",
    "    for g in myGroups:\n",
    "        for aa in AAGroup[g]:\n",
    "            AADict[aa] = g\n",
    "\n",
    "    features = [f1 + '.'+ f2 + '.' + f3 for f1 in myGroups for f2 in myGroups for f3 in myGroups]\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for f in features:\n",
    "        header.append(f)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        if len(sequence) < 3:\n",
    "            print('Error: for \"CTriad\" encoding, the input fasta sequences should be greater than 3. \\n\\n')\n",
    "            return 0\n",
    "        code = code + CalculateKSCTriad(sequence, 0, features, AADict)\n",
    "        encodings.append(code)\n",
    "\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b7d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Di-Dipeptide-based Encoding (DDE) for a given set of protein sequences (fastas)\n",
    "def DDE(fastas, **kw):\n",
    "    \n",
    "    # Define the 20 standard amino acids\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    # Define the codon usage for each amino acid\n",
    "    myCodons = {\n",
    "        'A': 4,\n",
    "        'C': 2,\n",
    "        'D': 2,\n",
    "        'E': 2,\n",
    "        'F': 2,\n",
    "        'G': 4,\n",
    "        'H': 2,\n",
    "        'I': 3,\n",
    "        'K': 2,\n",
    "        'L': 6,\n",
    "        'M': 1,\n",
    "        'N': 2,\n",
    "        'P': 4,\n",
    "        'Q': 2,\n",
    "        'R': 6,\n",
    "        'S': 6,\n",
    "        'T': 4,\n",
    "        'V': 4,\n",
    "        'W': 1,\n",
    "        'Y': 2\n",
    "    }\n",
    "    # Initialize the encodings and dipeptides\n",
    "    encodings = []\n",
    "    diPeptides = ['DDE_'+aa1 + aa2 for aa1 in AA for aa2 in AA]\n",
    "    header = [] + diPeptides\n",
    "\n",
    "    # Calculate the transition matrix (myTM) for dipeptides\n",
    "    myTM = []\n",
    "    for pair in diPeptides:\n",
    "        myTM.append((myCodons[pair[0]] / 61) * (myCodons[pair[1]] / 61))\n",
    "    # Create a dictionary for amino acid indices\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    # Calculate DDE encoding for each sequence in fastas\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        tmpCode = [0] * 400\n",
    "        for j in range(len(sequence) - 2 + 1):\n",
    "            tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+1]]] = tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+1]]] +1\n",
    "        if sum(tmpCode) != 0:\n",
    "            tmpCode = [i/sum(tmpCode) for i in tmpCode]\n",
    "\n",
    "        myTV = []\n",
    "        for j in range(len(myTM)):\n",
    "            myTV.append(myTM[j] * (1-myTM[j]) / (len(sequence) - 1))\n",
    "\n",
    "        for j in range(len(tmpCode)):\n",
    "            tmpCode[j] = (tmpCode[j] - myTM[j]) / math.sqrt(myTV[j])\n",
    "\n",
    "        code = code + tmpCode\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "# Disorder (Disorder) Protein disorder information was first predicted using external VSL2\n",
    "# DisorderB also required external program VSL2\n",
    "# DisorderC also required external program VSL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e2e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Dipeptide Composition (DPC) for a given set of protein sequences (fastas) with a specified gap\n",
    "def DPC(fastas, gap, **kw):\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    encodings = []\n",
    "    diPeptides = [aa1 + aa2 for aa1 in AA for aa2 in AA]\n",
    "    header = [] + diPeptides\n",
    "\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    \n",
    "    # Calculate DPC encoding for each sequence in fastas\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        tmpCode = [0] * 400\n",
    "        for j in range(len(sequence) - 2 + 1 - gap):\n",
    "            tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+gap+1]]] = tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+gap+1]]] +1\n",
    "        if sum(tmpCode) != 0:\n",
    "            tmpCode = [i/sum(tmpCode) for i in tmpCode]\n",
    "        code = code + tmpCode\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d933e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Equal Amino Acid Composition (EAAC) for a given set of protein sequences (fastas) with a specified window size\n",
    "def EAAC(fastas, window=5, **kw):\n",
    "    AA ='ACDEFGHIKLMNPQRSTVWY'\n",
    "    #AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for aa in AA:\n",
    "        header.append('EACC.'+aa)\n",
    "    # Calculate EAAC encoding for each sequence in fastas\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = []\n",
    "        for aa in AA:\n",
    "            tmp = 0\n",
    "            for j in range(len(sequence)):\n",
    "                if j < len(sequence) and j + window <= len(sequence):\n",
    "                    count = Counter(sequence[j:j+window])\n",
    "                    for key in count:\n",
    "                        count[key] = count[key] / len(sequence[j:j+window])\n",
    "                    tmp = tmp + count[aa]\n",
    "            code.append(tmp/len(sequence))\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f53fd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Equal Group Amino Acid Composition (EGAAC) for a given set of protein sequences (fastas) with a specified window size\n",
    "def EGAAC(fastas, window=5, **kw):\n",
    "    group = {\n",
    "        'alphaticr': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'postivecharger': 'KRH',\n",
    "        'negativecharger': 'DE',\n",
    "        'uncharger': 'STCPNQ'\n",
    "    }\n",
    "    groupKey = group.keys()\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for w in range(1, len(fastas[0][1]) - window + 2):\n",
    "        for g in groupKey:\n",
    "            header.append('SW.' + str(w) + '.' + g)\n",
    "\n",
    "    # Calculate EGAAC encoding for each sequence in fastas\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = []\n",
    "        for key in groupKey:\n",
    "            tmp=0\n",
    "            for j in range(len(sequence)):\n",
    "                if j + window <= len(sequence):\n",
    "                    count = Counter(sequence[j:j + window])\n",
    "                    myDict = {}\n",
    "                    #for key in groupKey:\n",
    "                    for aa in group[key]:\n",
    "                        myDict[key] = myDict.get(key, 0) + count[aa]\n",
    "\n",
    "\n",
    "                    #for key in groupKey:\n",
    "                    tmp = tmp + (myDict[key] / window)\n",
    "            code.append(tmp/len(sequence))\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c63aff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute R-value between two amino acids aa1 and aa2 using AADict and Matrix\n",
    "def Rvalue(aa1, aa2, AADict, Matrix):\n",
    "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aefbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Pseudo Amino Acid Composition (PAAC) for a given set of protein sequences (fastas) with a specified lambda value and weight (w)\n",
    "def PAAC(fastas, lambdaValue=5, w=0.05, **kw):\n",
    "    dataFile = 'data/PAAC.txt'\n",
    "\n",
    "    with open(dataFile) as f:\n",
    "        records = f.readlines()\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records)):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j - meanI) ** 2 for j in i]) / 20)\n",
    "        AAProperty1.append([(j - meanI) / fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for aa in AA:\n",
    "        header.append('Xc1.' + aa)\n",
    "    for n in range(1, lambdaValue + 1):\n",
    "        header.append('Xc2.lambda' + str(n))\n",
    "        \n",
    "    # Calculate PAAC encoding for each sequence in fastas\n",
    "    for i in fastas:\n",
    "        name, sequence= i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        theta = []\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            theta.append(\n",
    "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (\n",
    "                    len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307b1f2",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "This code is for evaluating the performance of various classifiers on protein sequence data. It consists of two functions: cv and test. The cv function performs cross-validation, and the test function is for testing the performance of classifiers on test data. The main part of the code reads data from protein sequences in FASTA format, extracts features using various feature extraction methods, trains multiple classifiers on these features, and evaluates their performance.\n",
    "\n",
    "Let's go through the code in detail:\n",
    "\n",
    "The cv function performs cross-validation on the given classifier (clf), data (X), labels (y), and the number of folds (nr_fold). It first initializes some lists to store performance metrics. Then, it splits the data into training and testing sets based on the fold number, fits the classifier on the training set, and computes various performance metrics (accuracy, sensitivity, specificity, Matthews correlation coefficient, and area under the ROC curve) on the test set. Finally, it returns the mean values of these performance metrics.\n",
    "\n",
    "The test function trains the given classifier (clf) on the training data (X, y) and evaluates it on the test data (Xt, yt). It calculates the same performance metrics as the cv function and returns them.\n",
    "\n",
    "The main part of the code starts by reading protein sequences from FASTA files and extracting features using various feature extraction methods, such as AAC, DPC, APAAC, CTDC, CTDD, CTDT, GAAC, KSCTriad, CTriad, DDE, and PAAC. It concatenates the features for both positive and negative samples to create the full feature set and their corresponding labels.\n",
    "\n",
    "Next, it reads test protein sequences and extracts the same features as for the training data.\n",
    "\n",
    "The code then trains and evaluates multiple classifiers, including RandomForestClassifier, ExtraTreesClassifier, SVC, LogisticRegression, XGBClassifier, and KNeighborsClassifier, on each of the feature sets (10 in total). It stores the predicted probabilities from these classifiers as additional features in featx.\n",
    "\n",
    "In summary, this code reads protein sequences, extracts features from them, and evaluates various classifiers on this feature set to predict whether the proteins are part of a specific class or not.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1dd39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for k-fold cross-validation\n",
    "def cv(clf, X, y, nr_fold):\n",
    "    ix = []\n",
    "    # Create an array with indices of the samples\n",
    "    for i in range(0, len(y)):\n",
    "        ix.append(i)\n",
    "    ix = np.array(ix)\n",
    "\n",
    "    # Initialize lists to store performance metrics\n",
    "    allACC = []\n",
    "    allSENS = []\n",
    "    allSPEC = []\n",
    "    allMCC = []\n",
    "    allAUC = []\n",
    "    \n",
    "    # Loop over each fold\n",
    "    for j in range(0, nr_fold):\n",
    "        # Create boolean masks for training and testing sets\n",
    "        train_ix = ((ix % nr_fold) != j)\n",
    "        test_ix = ((ix % nr_fold) == j)\n",
    "        \n",
    "        # Split the dataset into training and testing sets\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        \n",
    "        # Train the classifier\n",
    "        clf.fit(train_X, train_y)\n",
    "        \n",
    "        # Make predictions and probability predictions\n",
    "        p = clf.predict(test_X)\n",
    "        pr = clf.predict_proba(test_X)[:,1]\n",
    "        \n",
    "        # Initialize variables for confusion matrix elements\n",
    "        TP=0\n",
    "        FP=0\n",
    "        TN=0\n",
    "        FN=0\n",
    "        \n",
    "        # Calculate confusion matrix elements\n",
    "        for i in range(0,len(test_y)):\n",
    "            if test_y[i]==0 and p[i]==0:\n",
    "                TP+= 1\n",
    "            elif test_y[i]==0 and p[i]==1:\n",
    "                FN+= 1\n",
    "            elif test_y[i]==1 and p[i]==0:\n",
    "                FP+= 1\n",
    "            elif test_y[i]==1 and p[i]==1:\n",
    "                TN+= 1\n",
    "                \n",
    "        # Calculate performance metrics\n",
    "        ACC = (TP+TN)/(TP+FP+TN+FN)\n",
    "        SENS = TP/(TP+FN)\n",
    "        SPEC = TN/(TN+FP)\n",
    "        det = math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "        if (det == 0):\n",
    "            MCC = 0\n",
    "        else:\n",
    "            MCC = ((TP*TN)-(FP*FN))/det\n",
    "        AUC = roc_auc_score(test_y,pr)\n",
    "        \n",
    "        # Append performance metrics to the lists\n",
    "        allACC.append(ACC)\n",
    "        allSENS.append(SENS)\n",
    "        allSPEC.append(SPEC)\n",
    "        allMCC.append(MCC)\n",
    "        allAUC.append(AUC)\n",
    "        \n",
    "    # Return the mean of the performance metrics\n",
    "    return np.mean(allACC),np.mean(allSENS),np.mean(allSPEC),np.mean(allMCC),np.mean(allAUC)\n",
    "\n",
    "\n",
    "# Function for evaluating a classifier without cross-validation\n",
    "def test(clf, X, y, Xt, yt):\n",
    "    # Assign the training and testing sets\n",
    "    train_X, test_X = X, Xt\n",
    "    train_y, test_y = y, yt\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(train_X, train_y)\n",
    "    \n",
    "    # Make predictions and probability predictions\n",
    "    p = clf.predict(test_X)\n",
    "    pr = clf.predict_proba(test_X)[:,1]\n",
    "    \n",
    "    # Initialize variables for confusion matrix elements\n",
    "    TP=0\n",
    "    FP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    \n",
    "    # Calculate confusion matrix elements\n",
    "    for i in range(0,len(test_y)):\n",
    "        if test_y[i]==0 and p[i]==0:\n",
    "            TP+= 1\n",
    "        elif test_y[i]==0 and p[i]==1:\n",
    "            FN+= 1\n",
    "        elif test_y[i]==1 and p[i]==0:\n",
    "            FP+= 1\n",
    "        elif test_y[i]==1 and p[i]==1:\n",
    "            TN+= 1\n",
    "            \n",
    "    # Calculate performance metrics\n",
    "    ACC = (TP+TN)/(TP+FP+TN+FN)\n",
    "    SENS = TP/(TP+FN)\n",
    "    SPEC = TN/(TN+FP)\n",
    "    det = math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    if (det == 0):\n",
    "        MCC = 0\n",
    "    else:\n",
    "        MCC = ((TP*TN)-(FP*FN))/det\n",
    "    AUC = roc_auc_score(test_y,pr)\n",
    "\n",
    "    # Return the performance metrics\n",
    "    return ACC, SENS, SPEC, MCC, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f5f5a",
   "metadata": {},
   "source": [
    "This code reads protein sequences from FASTA files and calculates various features for each sequence. These features are then concatenated to form a feature vector for each sequence.\n",
    "\n",
    "The code starts by initializing an empty list called header and reading protein sequences from a file named 'data/TR_P_132.fasta'. Then, it computes different features for these sequences using functions like AAC, DPC, APAAC, CTDC, CTDD, CTDT, GAAC, KSCTriad, CTriad, DDE, and PAAC. The features and their corresponding headers are stored in allfeat_pos and allfeat_head, respectively.\n",
    "\n",
    "The same process is repeated for another set of protein sequences stored in 'data/TR_N_305.fasta', and the features are stored in allfeat_neg. Then, the positive and negative features are concatenated together, and their corresponding class labels are created. The class labels for positive sequences are set to 0, and for negative sequences, they are set to 1. The final feature matrix X and the class labels y are generated.\n",
    "\n",
    "This process is then repeated for another set of protein sequences from files named 'data/TS_P_33.fasta' and 'data/TS_N_77.fasta'. The final feature matrix Xt and the class labels yt are generated for these sequences.\n",
    "\n",
    "In summary, this code reads protein sequences from multiple FASTA files, computes various features for the sequences, and concatenates the features to create feature matrices and corresponding class labels for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39886051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 1849)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# AAC, DPC, APAAC,PAAC,DDE,GAAC,KSCtraid, Ctraid, GDPC, CTDC, CTDD, CTDT,\n",
    "header = []\n",
    "fasta = read_protein_sequences('data/TR_P_132.fasta')\n",
    "feat0, h = AAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = feat0\n",
    "allfeat_head = header[0]\n",
    "feat1, h = DPC(fasta,0)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat1),axis=1)\n",
    "allfeat_head = allfeat_head + header[1]\n",
    "feat2, h = APAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat2),axis=1)\n",
    "allfeat_head = allfeat_head + header[2]\n",
    "feat3, h = CTDC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat3),axis=1)\n",
    "allfeat_head = allfeat_head + header[3]\n",
    "feat4, h = CTDD(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat4),axis=1)\n",
    "allfeat_head = allfeat_head + header[4]\n",
    "feat5, h = CTDT(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat5),axis=1)\n",
    "allfeat_head = allfeat_head + header[5]\n",
    "#feat, h = GDPC(fasta)\n",
    "#header.append(h)\n",
    "#allfeat_pos = np.concatenate((allfeat_pos,feat),axis=1)\n",
    "#allfeat_head = allfeat_head + header[6]\n",
    "feat6, h = GAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat6[:,1:]),axis=1)\n",
    "allfeat_head = allfeat_head + header[6]\n",
    "feat7, h = KSCTriad(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat7[:,1:]),axis=1)\n",
    "allfeat_head = allfeat_head + header[7]\n",
    "feat8, h = CTriad(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat8),axis=1)\n",
    "allfeat_head = allfeat_head + header[8]\n",
    "feat9, h = DDE(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat9),axis=1)\n",
    "allfeat_head = allfeat_head + header[9]\n",
    "feat10, h = PAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat10),axis=1)\n",
    "allfeat_head = allfeat_head + header[10]\n",
    "CTD_featurP=np.concatenate((feat3,feat4,feat5),axis=1)\n",
    "\n",
    "fasta = read_protein_sequences('data/TR_N_305.fasta')\n",
    "feat0, headerx = AAC(fasta)\n",
    "allfeat_neg = feat0\n",
    "feat1, headerx = DPC(fasta,0)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat1),axis=1)\n",
    "feat2, headerx = APAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat2),axis=1)\n",
    "feat3, headerx = CTDC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat3),axis=1)\n",
    "feat4, headerx = CTDD(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat4),axis=1)\n",
    "feat5, headerx = CTDT(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat5),axis=1)\n",
    "#feat, headerx =GDPC(fasta)\n",
    "#allfeat_neg = np.concatenate((allfeat_neg,feat),axis=1)\n",
    "feat6, headerx = GAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat6[:,1:]),axis=1)\n",
    "feat7, headerx = KSCTriad(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat7[:,1:]),axis=1)\n",
    "feat8, headerx = CTriad(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat8),axis=1)\n",
    "feat9, headerx = DDE(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat9),axis=1)\n",
    "feat10, headerx = PAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg,feat10),axis=1)\n",
    "f = []\n",
    "before = 0\n",
    "for i in range(0,10):\n",
    "    after = before + len(header[i])\n",
    "    f.append(list(range(before, after)))\n",
    "    before = after\n",
    "allfeat = np.concatenate((allfeat_pos, allfeat_neg), axis=0)\n",
    "allclassT = np.concatenate((np.zeros(len(allfeat_pos)), np.ones(len(allfeat_neg))))\n",
    "X = allfeat\n",
    "y = allclassT\n",
    "ix = []\n",
    "for i in range(0, len(y)):\n",
    "    ix.append(i)\n",
    "ix = np.array(ix)\n",
    "# Generate Test features\n",
    "header = []\n",
    "fasta = read_protein_sequences('data/TS_P_33.fasta')\n",
    "feat0, h = AAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = feat0\n",
    "allfeat_head = header[0]\n",
    "feat1, h = DPC(fasta,0)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat1),axis=1)\n",
    "allfeat_head = allfeat_head + header[1]\n",
    "feat2, h = APAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat2),axis=1)\n",
    "allfeat_head = allfeat_head + header[2]\n",
    "feat3, h = CTDC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat3),axis=1)\n",
    "allfeat_head = allfeat_head + header[3]\n",
    "feat4, h = CTDD(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat4),axis=1)\n",
    "allfeat_head = allfeat_head + header[4]\n",
    "feat5, h = CTDT(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat5),axis=1)\n",
    "allfeat_head = allfeat_head + header[5]\n",
    "#feat, h = GDPC(fasta)\n",
    "#header.append(h)\n",
    "#allfeat_pos = np.concatenate((allfeat_pos,feat),axis=1)\n",
    "#allfeat_head = allfeat_head + header[6]\n",
    "feat6, h = GAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat6[:,1:]),axis=1)\n",
    "allfeat_head = allfeat_head + header[6]\n",
    "feat7, h = KSCTriad(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat7[:,1:]),axis=1)\n",
    "allfeat_head = allfeat_head + header[7]\n",
    "feat8, h = CTriad(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat8),axis=1)\n",
    "allfeat_head = allfeat_head + header[8]\n",
    "feat9, h = DDE(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat9),axis=1)\n",
    "allfeat_head = allfeat_head + header[9]\n",
    "feat10, h = PAAC(fasta)\n",
    "header.append(h)\n",
    "allfeat_pos = np.concatenate((allfeat_pos,feat10),axis=1)\n",
    "allfeat_head = allfeat_head + header[10]\n",
    "\n",
    "\n",
    "fasta = read_protein_sequences('data/TS_N_77.fasta')\n",
    "feat0, header = AAC(fasta)\n",
    "allfeat_neg = feat0\n",
    "feat1, header = DPC(fasta, 0)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat1), axis=1)\n",
    "feat2, h = APAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat2), axis=1)\n",
    "feat3, h = CTDC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat3), axis=1)\n",
    "feat4, h = CTDD(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat4), axis=1)\n",
    "feat5, h = CTDT(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat5), axis=1)\n",
    "#feat, h = GDPC(fasta)\n",
    "#allfeat_neg = np.concatenate((allfeat_neg, feat), axis=1)\n",
    "feat6, h = GAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat6[:,1:]), axis=1)\n",
    "feat7, h = KSCTriad(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat7[:,1:]), axis=1)\n",
    "feat8, h = CTriad(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat8), axis=1)\n",
    "feat9, h = DDE(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat9), axis=1)\n",
    "feat10, h = PAAC(fasta)\n",
    "allfeat_neg = np.concatenate((allfeat_neg, feat10), axis=1)\n",
    "\n",
    "allfeat = np.concatenate((allfeat_pos, allfeat_neg), axis=0)\n",
    "allclass = np.concatenate((np.ones(len(allfeat_pos)), np.zeros(len(allfeat_neg))))\n",
    "\n",
    "Xt = allfeat\n",
    "yt = allclass\n",
    "\n",
    "print(np.shape(allfeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af13e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b349ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 60)\n"
     ]
    }
   ],
   "source": [
    "def get_featx(Xt):\n",
    "    featx = []\n",
    "\n",
    "    for i in range(0, 10):\n",
    "        Xs = X[:, f[i]]\n",
    "        Xts = Xt[:, f[i]]\n",
    "        clf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "        clf.fit(Xs, y)\n",
    "        pr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat = pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        if (i == 0):\n",
    "            featx = feat\n",
    "        else:\n",
    "              featx = np.concatenate((featx, feat), axis=1)\n",
    "\n",
    "        clf = ExtraTreesClassifier(n_estimators=500, random_state=0)\n",
    "        clf.fit(Xs, y)\n",
    "        pr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat = pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        featx = np.concatenate((featx, feat), axis=1)\n",
    "\n",
    "        clf = SVC(probability=True, random_state=0)\n",
    "        clf.fit(Xs, y)\n",
    "        ppr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat = pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        featx = np.concatenate((featx, feat), axis=1)\n",
    "\n",
    "        clf = LogisticRegression(random_state=0, max_iter=5000)\n",
    "        clf.fit(Xs, y)\n",
    "        pr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat = pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        featx = np.concatenate((featx, feat), axis=1)\n",
    "\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(Xs, y)\n",
    "        pr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat = pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        featx = np.concatenate((featx, feat), axis=1)\n",
    "\n",
    "        clf = KNeighborsClassifier(weights=\"distance\", algorithm=\"auto\")\n",
    "        clf.fit(Xs, y)\n",
    "        pr = clf.predict_proba(Xts)[:, 0]\n",
    "        pr_c = clf.predict(Xts)\n",
    "        feat= pr\n",
    "        feat = np.reshape(feat, (len(Xts), 1))\n",
    "        featx = np.concatenate((featx, feat), axis=1)\n",
    "    \n",
    "    return featx\n",
    "\n",
    "featx = get_featx(Xt)\n",
    "Test_PF = featx\n",
    "\n",
    "print(np.shape(Test_PF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "356ad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aab230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(featx):\n",
    "    mask=[2,3,4,5,9,10,12,14,15,18,24,25,28,34,46,47,48,53,56,57]\n",
    "    Selected_feat = featx[:,mask]\n",
    "    return Selected_feat\n",
    "\n",
    "Xt = apply_mask(featx)\n",
    "yt = allclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3e781e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# import utils.tools as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ca9e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert probability scores to class labels\n",
    "def categorical_probas_to_classes(p):\n",
    "    # Use numpy's argmax function to find the index of the highest probability\n",
    "    # for each row (sample) along the specified axis (axis=1, i.e., columns)\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "# Function to convert class labels to one-hot encoded format\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    # Convert the input array (y) to a numpy array with datatype 'int'\n",
    "    y = np.array(y, dtype='int')\n",
    "\n",
    "    # If the number of classes is not specified, find the highest class label\n",
    "    # and add 1 to get the total number of classes\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y) + 1\n",
    "\n",
    "    # Create a zero-filled numpy array with the shape (number of samples, number of classes)\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "\n",
    "    # Iterate through each class label in the input array (y)\n",
    "    for i in range(len(y)):\n",
    "        # Set the corresponding element in the one-hot encoded array to 1\n",
    "        Y[i, y[i]] = 1\n",
    "\n",
    "    # Return the one-hot encoded array\n",
    "    return Y\n",
    "\n",
    "# Function to calculate performance metrics for a binary classification task\n",
    "def calculate_performace(test_num, pred_y, labels):\n",
    "    # Initialize true positive (tp), false positive (fp), true negative (tn), and false negative (fn) counts to 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    # Iterate through each predicted and true label pair\n",
    "    for index in range(test_num):\n",
    "        # If the true label is positive (1)\n",
    "        if labels[index] == 1:\n",
    "            # If the prediction is also positive (1), increment the true positive count\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp + 1\n",
    "            # If the prediction is negative (0), increment the false negative count\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        # If the true label is negative (0)\n",
    "        else:\n",
    "            # If the prediction is also negative (0), increment the true negative count\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn + 1\n",
    "            # If the prediction is positive (1), increment the false positive count\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "\n",
    "    # Calculate performance metrics using the tp, fp, tn, and fn counts\n",
    "    acc = float(tp + tn) / test_num  # accuracy\n",
    "    precision = float(tp) / (tp + fp + 1e-06)  # precision\n",
    "    npv = float(tn) / (tn + fn + 1e-06)  # negative predictive value\n",
    "    sensitivity = float(tp) / (tp + fn + 1e-06)  # sensitivity (recall)\n",
    "    specificity = float(tn) / (tn + fp + 1e-06)  # specificity\n",
    "    mcc = float(tp * tn - fp * fn) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + 1e-06)  # Matthews correlation coefficient\n",
    "    # calculates the F1 score, which is a measure of a model's accuracy on a binary classification task. It is the harmonic mean of precision and recall, providing a balance between these two metrics.\n",
    "    f1 = float(tp * 2) / (tp * 2 + fp + fn + 1e-06)\n",
    "    \n",
    "    return acc, precision, npv, sensitivity, specificity, mcc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5882d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[0.96939591 0.96340235 0.8432916  0.57013616 0.79242889 0.93613578\n",
      " 0.65183562 0.71516303 0.78323884 0.95152008 0.90073541 0.74242483\n",
      " 0.76343362 0.96275142 0.06687006 0.97843749 0.07528113 0.90504876\n",
      " 0.90565922 0.96983735 0.89313072 0.96624587 0.66471018 0.95175055\n",
      " 0.94350782 0.95371278 0.71630446 0.39438815 0.78327564 0.10252572\n",
      " 0.92534627 0.94705653 0.93306811 0.14076612 0.09428377 0.13179319\n",
      " 0.08164489 0.09621154 0.06821761 0.05421529 0.19905328 0.09368869\n",
      " 0.08917437 0.08216754 0.08878637 0.27023395 0.24519135 0.16464773\n",
      " 0.06010027 0.3579558  0.11129866 0.4547526  0.10849668 0.09087592\n",
      " 0.0757956  0.07530478 0.10436246 0.68109568 0.18186709 0.10441713\n",
      " 0.10063966 0.08983897 0.05387055 0.45161475 0.06093643 0.43448213\n",
      " 0.08812225 0.82899185 0.33678549 0.28292898 0.0888146  0.06280906\n",
      " 0.09181815 0.08730886 0.12135003 0.13928096 0.07732852 0.08639498\n",
      " 0.08694462 0.36958821 0.08311997 0.09231518 0.07361113 0.08195284\n",
      " 0.29091711 0.27788856 0.09179208 0.24742633 0.07423048 0.02766976\n",
      " 0.84532842 0.08702377 0.26993163 0.7048675  0.07717779 0.09987291\n",
      " 0.12696347 0.09175498 0.09199938 0.08761761 0.06170784 0.40517314\n",
      " 0.09063283 0.28244078 0.1000225  0.08349614 0.07919994 0.08350668\n",
      " 0.09184852 0.08924611]\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "Non_AMY\n",
      "-------------------------------\n",
      "AmyPredFRL_Test_Results:acc=0.927273,sensitivity=0.878788,specificity=0.948052,mcc=0.826840,roc_auc=0.920110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshf\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.23.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stack the test data vertically\n",
    "xtest = np.vstack(Xt)\n",
    "y_test = np.vstack(yt)\n",
    "\n",
    "# Get the shape of the test data\n",
    "[m, n] = np.shape(xtest)\n",
    "\n",
    "# Load the pre-trained model from disk\n",
    "ldmodel = pickle.load(open(\"model/pima.pickle_model_svm_PF.dat\", \"rb\"))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# Initialize an empty list to store the separate scores\n",
    "Sepscores = []\n",
    "\n",
    "# Calculate the predicted probabilities for each sample in the test data\n",
    "y_score = ldmodel.predict_proba(xtest)\n",
    "probablity = y_score[:, 1]\n",
    "print(probablity)\n",
    "\n",
    "# Set a threshold for classification\n",
    "threshold = 0.50\n",
    "\n",
    "# Print the class labels based on the threshold\n",
    "for i in range(m):\n",
    "    if probablity[i] >= threshold:\n",
    "        print('AMY')\n",
    "        print('-------------------------------')\n",
    "    else:\n",
    "        print('Non_AMY')\n",
    "        print('-------------------------------')\n",
    "\n",
    "# Convert the probability scores to class labels\n",
    "y_class = categorical_probas_to_classes(y_score)\n",
    "\n",
    "# Calculate the false positive rate (fpr) and true positive rate (tpr) for the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "\n",
    "# Calculate the area under the ROC curve (roc_auc)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "acc, precision, npv, sensitivity, specificity, mcc, f1 = calculate_performace(len(y_class), y_class, y_test)\n",
    "\n",
    "# Append the performance metrics to the separate scores list\n",
    "Sepscores.append([acc, sensitivity, specificity, mcc, roc_auc])\n",
    "\n",
    "# Print the performance metrics\n",
    "print('AmyPredFRL_Test_Results:acc=%f,sensitivity=%f,specificity=%f,mcc=%f,roc_auc=%f'\n",
    "      % (acc, sensitivity, specificity, mcc, roc_auc))\n",
    "\n",
    "# Calculate the mean of the separate scores\n",
    "scores = np.array(Sepscores)\n",
    "result1 = np.mean(scores, axis=0)\n",
    "H1 = result1.tolist()\n",
    "Sepscores.append(H1)\n",
    "\n",
    "# Store the final results in a list\n",
    "result = Sepscores\n",
    "\n",
    "# Create a pandas DataFrame to store the results\n",
    "colum = ['ACC', 'Sn', 'Sp', 'MCC', 'AUC']\n",
    "data_csv = pd.DataFrame(columns=colum, data=result)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "data_csv.to_csv('AmyPredFRL_Test_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb87c24",
   "metadata": {},
   "source": [
    "# Run AMYPred-FRL\n",
    "To use the program above to predict whether a given sequence is an amyloid, you need to preprocess the input sequence and feed it to the trained model. Assuming that the input sequence is in the same format as the data used to train the model, you can follow these steps:\n",
    "\n",
    "Preprocess the input sequence.\n",
    "Transform the sequence into a suitable format for the model.\n",
    "Pass the transformed sequence through the model.\n",
    "Evaluate the output probability and apply the threshold to determine the class label.\n",
    "## Import from FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ff5138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb645b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sequence_from_fasta(fasta_file):\n",
    "    # Read protein sequences (into original format)\n",
    "    fasta = read_protein_sequences(fasta_file)\n",
    "    \n",
    "    # Save the IDs and description\n",
    "    metadata = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    \n",
    "    \n",
    "    # convert fasta ids to integers (might want to change this)\n",
    "    for i in range(len(fasta)):\n",
    "        fasta[i][0] = str(i)\n",
    "        \n",
    "    # Compute features\n",
    "    header = []\n",
    "    features = []\n",
    "\n",
    "    feat_fns = [AAC, DPC, APAAC, CTDC, CTDD, CTDT, GAAC, KSCTriad, CTriad, DDE, PAAC]\n",
    "    for feat_fn in feat_fns:\n",
    "        \n",
    "        if feat_fn == DPC:\n",
    "            feat, h = feat_fn(fasta, gap=0)\n",
    "        else:\n",
    "            feat, h = feat_fn(fasta)\n",
    "            # Exclude the first column for GAAC and KSCTriad\n",
    "            if feat_fn in [GAAC, KSCTriad]:\n",
    "                feat = feat[:, 1:]\n",
    "                \n",
    "            \n",
    "        header.append(h)\n",
    "        features.append(feat)\n",
    "    \n",
    "\n",
    "    # Combine all features\n",
    "    allfeat = np.concatenate(features, axis=1)\n",
    "\n",
    "    return allfeat, fasta, metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba91fb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp|P0DTC1|R1A_SARS2 Replicase polyprotein 1a OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 PE=1 SV=1\n",
      "MESLVPGFNE...\n",
      "Predicted class: Non_AMY (0.07854196160776328) \n",
      "\n",
      "\n",
      "sp|P0DTC2|SPIKE_SARS2 Spike glycoprotein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=S PE=1 SV=1\n",
      "MFVFLVLLPL...\n",
      "Predicted class: Non_AMY (0.08998793660107443) \n",
      "\n",
      "\n",
      "sp|P0DTC3|AP3A_SARS2 ORF3a protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=3a PE=1 SV=1\n",
      "MDLFMRIFTI...\n",
      "Predicted class: Non_AMY (0.31199571900901224) \n",
      "\n",
      "\n",
      "sp|P0DTC4|VEMP_SARS2 Envelope small membrane protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=E PE=1 SV=1\n",
      "MYSFVSEETG...\n",
      "Predicted class: AMY (0.9440942322412373) \n",
      "\n",
      "\n",
      "sp|P0DTC5|VME1_SARS2 Membrane protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=M PE=1 SV=1\n",
      "MADSNGTITV...\n",
      "Predicted class: Non_AMY (0.11995682531828883) \n",
      "\n",
      "\n",
      "sp|P0DTC6|NS6_SARS2 ORF6 protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=6 PE=1 SV=1\n",
      "MFHLVDFQVT...\n",
      "Predicted class: Non_AMY (0.028578580920875448) \n",
      "\n",
      "\n",
      "sp|P0DTC7|NS7A_SARS2 ORF7a protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=7a PE=1 SV=1\n",
      "MKIILFLALI...\n",
      "Predicted class: AMY (0.9661993547730923) \n",
      "\n",
      "\n",
      "sp|P0DTC8|NS8_SARS2 ORF8 protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=8 PE=1 SV=1\n",
      "MKFLVFLGII...\n",
      "Predicted class: AMY (0.9200096983310324) \n",
      "\n",
      "\n",
      "sp|P0DTC9|NCAP_SARS2 Nucleoprotein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=N PE=1 SV=1\n",
      "MSDNGPQNQR...\n",
      "Predicted class: Non_AMY (0.12852748072292502) \n",
      "\n",
      "\n",
      "sp|P0DTD1|R1AB_SARS2 Replicase polyprotein 1ab OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=rep PE=1 SV=1\n",
      "MESLVPGFNE...\n",
      "Predicted class: Non_AMY (0.08683904987030353) \n",
      "\n",
      "\n",
      "sp|P0DTD2|ORF9B_SARS2 ORF9b protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=9b PE=1 SV=1\n",
      "MDPKISEMHP...\n",
      "Predicted class: AMY (0.9050497507539227) \n",
      "\n",
      "\n",
      "sp|A0A663DJA2|ORF10_SARS2 Putative ORF10 protein OS=Severe acute respiratory syndrome coronavirus 2 OX=2697049 GN=ORF10 PE=5 SV=1\n",
      "MGYINVFAFP...\n",
      "Predicted class: Non_AMY (0.7414965077092597) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input FASTA file\n",
    "input_fasta_file = \"data/sars-cov-2.fasta\"\n",
    "\n",
    "# Preprocess the input sequence\n",
    "preprocessed_sequence, fasta, metadata = preprocess_sequence_from_fasta(input_fasta_file)\n",
    "# print(np.shape(preprocessed_sequence))\n",
    "# selected feature\n",
    "selected_features = apply_mask(get_featx(preprocessed_sequence))\n",
    "# print(np.shape(selected_features))\n",
    "\n",
    "# Pass the preprocessed_sequence to the model for prediction\n",
    "y_score = ldmodel.predict_proba(selected_features)\n",
    "probablity = y_score[:, 1]\n",
    "\n",
    "# Apply the threshold to determine the class label\n",
    "threshold = 0.90\n",
    "for i, prob in enumerate(probablity):\n",
    "    \n",
    "    print(metadata[i].description)\n",
    "    print(metadata[i].seq[0:10] + '...')\n",
    "    \n",
    "    predicted_class = \"AMY\" if prob >= threshold else \"Non_AMY\"\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Predicted class: {predicted_class} ({prob}) \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80804b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a963a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58bd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b948cd",
   "metadata": {},
   "source": [
    "## Input protein sequence directly \n",
    "in fasta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef3047e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sequence_from_string(fasta_string):\n",
    "\n",
    "    # Read protein sequences\n",
    "    fasta = read_protein_sequences(input_string=fasta_string)\n",
    "    \n",
    "    # convert fasta ids to integers (might want to change this)\n",
    "    for i in range(len(fasta)):\n",
    "        fasta[i][0] = str(i)\n",
    "\n",
    "    # Compute features\n",
    "    header = []\n",
    "    features = []\n",
    "\n",
    "    feat_fns = [AAC, DPC, APAAC, CTDC, CTDD, CTDT, GAAC, KSCTriad, CTriad, DDE, PAAC]\n",
    "    for feat_fn in feat_fns:\n",
    "        \n",
    "        if feat_fn == DPC:\n",
    "            feat, h = feat_fn(fasta, gap=0)\n",
    "        else:\n",
    "            feat, h = feat_fn(fasta)\n",
    "            # Exclude the first column for GAAC and KSCTriad\n",
    "            if feat_fn in [GAAC, KSCTriad]:\n",
    "                feat = feat[:, 1:]\n",
    "                \n",
    "            \n",
    "        header.append(h)\n",
    "        features.append(feat)\n",
    "\n",
    "    # Combine all features\n",
    "    allfeat = np.concatenate(features, axis=1)\n",
    "\n",
    "    return allfeat, fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61ff538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISN\\nCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\\nYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPC\\nNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNL'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFS\n",
    "NVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIV\n",
    "NNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLE\n",
    "GKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQT\n",
    "LLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETK\n",
    "CTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISN\n",
    "CVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\n",
    "YNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPC\n",
    "NGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVN\n",
    "FNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITP\n",
    "GTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSY\n",
    "ECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTI\n",
    "SVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQE\n",
    "VFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDC\n",
    "LGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAM\n",
    "QMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALN\n",
    "TLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRA\n",
    "SANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPA\n",
    "ICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDP\n",
    "LQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDL\n",
    "QELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDD\n",
    "SEPVLKGVKLHYT\"\"\"[306:541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0612012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your protein sequence:\n",
      "TLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISN\\nCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\\nYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPC\\nNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNL\n",
      "Predicted class: AMY (0.9806428088439684) \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9806428088439684"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input a single protein sequence in FASTA format\n",
    "print(\"Please enter your protein sequence:\")\n",
    "fasta_string = input()\n",
    "\n",
    "def sequence_amyloidogenicity(fasta_string, threshold = 0.90):\n",
    "    \n",
    "    #reformat to fasta if necessary\n",
    "    if fasta_string[0] != '>':\n",
    "        fasta_string = '>1\\n' + fasta_string\n",
    "\n",
    "    \"\"\" Example Input\n",
    "    DYIINLIIKNL\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess the input sequence\n",
    "    preprocessed_sequence, fasta = preprocess_sequence_from_string(fasta_string)\n",
    "    # print(np.shape(preprocessed_sequence))\n",
    "    # selected feature\n",
    "    selected_features = apply_mask(get_featx(preprocessed_sequence))\n",
    "    # print(np.shape(selected_features))\n",
    "\n",
    "    # Pass the preprocessed_sequence to the model for prediction\n",
    "    y_score = ldmodel.predict_proba(selected_features)\n",
    "    probablity = y_score[:, 1]\n",
    "\n",
    "    # Apply the threshold to determine the class label\n",
    "    for i, prob in enumerate(probablity):\n",
    "\n",
    "    #     print(fasta[i])\n",
    "\n",
    "        predicted_class = \"AMY\" if prob >= threshold else \"Non_AMY\"\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"Predicted class: {predicted_class} ({prob}) \\n\\n\")\n",
    "    \n",
    "    return prob\n",
    "\n",
    "sequence_amyloidogenicity(fasta_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfab0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e1bf659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.1.1.529.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFXYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSFKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.5146373585504178) \n",
      "\n",
      "\n",
      "B.1.1.7.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQTSITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "B.1.351.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQTSITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLRVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.541095579369114) \n",
      "\n",
      "\n",
      "B.1.617.2.fasta S\n",
      "MFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLAAVAYFNMVYMPASWVMRIMTWLDMVDTSLSGFKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNR\n",
      "Predicted class: Non_AMY (0.547158738278449) \n",
      "\n",
      "\n",
      "BA.2.75.fasta S\n",
      "\n",
      "BQ..1.fasta S\n",
      "MFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLSGLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNR\n",
      "CH.1.1.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPFTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.5071197084113472) \n",
      "\n",
      "\n",
      "P.1.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPLTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQTSITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.5367103801147773) \n",
      "\n",
      "\n",
      "W.4.fasta S\n",
      "MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSVLEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICA\n",
      "Predicted class: Non_AMY (0.08845072331726953) \n",
      "\n",
      "\n",
      "XBB.1.5.fasta S\n",
      "MFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPFTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLSGLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNR\n",
      "XBB.1.9.1.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPFTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.5071197084113472) \n",
      "\n",
      "\n",
      "XBB.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPFTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n",
      "Predicted class: Non_AMY (0.5071197084113472) \n",
      "\n",
      "\n",
      "XBF.fasta S\n",
      "MVMFTPLVPFWITIAYIICISTKHFYWFFSNYLKRRVVFNGVSFSTFEEAALCTFLLNKEMYLKLRSDVLLPFTQYNRYLALYNKYKYFSGAMDTTSYREAACCHLAKALNDFSNSGSDVLYQPPQISITSAVLQSGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRHNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLLTILTSLLVLVQSTQWSLFFFLYENAFLPFAMGIIAMSAFAMMFVKHKHAFLCLFLLPSLATVAYFNMVYMPASWVMRIMTWLDMVDTSLKLKDCVMYASAVVLLILMTARTVYDDGARRVWTLMNVLTLVYKVYYGNALDQAISMWALIISVTSNYSGVVTTVMFLARGIVFMCVEYCPIFFITGNTLQCIMLVYCFLGYFCTCYFGLFCLLNRY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Non_AMY (0.5071197084113472) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../voc_proteomes.json', 'r') as file:\n",
    "    voc_proteomes = json.load(file) \n",
    "    \n",
    "for voc in voc_proteomes:\n",
    "    print(f'{voc} S')\n",
    "    try:\n",
    "        seq = voc_proteomes[voc][\"S\"][0:672]\n",
    "        print(seq)\n",
    "        sequence_amyloidogenicity(seq)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce8306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "560b4e3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
